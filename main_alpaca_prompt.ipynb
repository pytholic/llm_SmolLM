{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # pip install transformers\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# checkpoint = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
    "\n",
    "# device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=\"./.cache\")\n",
    "# tokenizer.eos_token_id = 0\n",
    "\n",
    "# # for multiple GPUs install accelerate and do `model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\")`\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=\"./.cache\", max_length=100).to(device)\n",
    "\n",
    "# messages = [{\"role\": \"user\", \"content\": \"List the steps to bake a chocolate cake from scratch.\"}]\n",
    "# input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "# # input_text = format_input(data[50])\n",
    "# print(input_text)\n",
    "# inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "# # outputs = model(inputs)\n",
    "# # # print(outputs)\n",
    "# # outputs = model.generate(inputs, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True, output_scores=True, return_dict_in_generate=True)\n",
    "# outputs = model.generate(inputs, max_new_tokens=1000,do_sample=False)\n",
    "# # print(outputs[0])\n",
    "# # # print(outputs.scores)\n",
    "# print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import json\n",
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Apply alpaca prompt style\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[0])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[0]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Partitioning the dataset\n",
    "\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1) # 10%\n",
    "val_portion = len(data) - train_portion - test_portion # 5%\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching the dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "49152\n"
     ]
    }
   ],
   "source": [
    "# Get eos token id (will be used for padding also)\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-360M-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=\"./.cache\")\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 2, 2, 2],\n",
      "        [7, 8, 9, 2, 2]]), tensor([[   1,    2,    3,    4, -100],\n",
      "        [   6,    2, -100, -100, -100],\n",
      "        [   8,    9,    2, -100, -100]]))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 102]) torch.Size([8, 102])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=\"./.cache\", max_length=1024).to(device)\n",
    "model_generate = partial(model.generate, max_new_tokens=256, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lunit/home/pytholic/miniconda3/envs/llm_smollm/lib/python3.11/site-packages/transformers/generation/utils.py:1376: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model_generate(inputs)\n",
    "outputs = tokenizer.decode(outputs[0])\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    outputs = model(input_batch)\n",
    "    logits = outputs.logits \n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "#     inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "# outputs = model.generate(inputs, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True, output_scores=True, return_dict_in_generate=True)\n",
    "# outputs = tokenizer.decode(outputs.sequences[0])\n",
    "# print(outputs)\n",
    "    encoded = tokenizer.encode(start_context, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_generate(encoded)\n",
    "        decoded_text = tokenizer.decode(outputs[0])\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.4040127277374266\n",
      "Validation loss: 2.3871003150939942\n"
     ]
    }
   ],
   "source": [
    "# check the initial loss\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.937, Val loss 1.914\n",
      "Ep 1 (Step 000005): Train loss 0.912, Val loss 0.859\n",
      "Ep 1 (Step 000010): Train loss 0.598, Val loss 0.703\n",
      "Ep 1 (Step 000015): Train loss 0.602, Val loss 0.661\n",
      "Ep 1 (Step 000020): Train loss 0.536, Val loss 0.657\n",
      "Ep 1 (Step 000025): Train loss 0.571, Val loss 0.634\n",
      "Ep 1 (Step 000030): Train loss 0.636, Val loss 0.617\n",
      "Ep 1 (Step 000035): Train loss 0.579, Val loss 0.603\n",
      "Ep 1 (Step 000040): Train loss 0.505, Val loss 0.595\n",
      "Ep 1 (Step 000045): Train loss 0.473, Val loss 0.581\n",
      "Ep 1 (Step 000050): Train loss 0.504, Val loss 0.575\n",
      "Ep 1 (Step 000055): Train loss 0.592, Val loss 0.569\n",
      "Ep 1 (Step 000060): Train loss 0.564, Val loss 0.556\n",
      "Ep 1 (Step 000065): Train loss 0.498, Val loss 0.549\n",
      "Ep 1 (Step 000070): Train loss 0.440, Val loss 0.545\n",
      "Ep 1 (Step 000075): Train loss 0.449, Val loss 0.543\n",
      "Ep 1 (Step 000080): Train loss 0.473, Val loss 0.542\n",
      "Ep 1 (Step 000085): Train loss 0.419, Val loss 0.539\n",
      "Ep 1 (Step 000090): Train loss 0.404, Val loss 0.530\n",
      "Ep 1 (Step 000095): Train loss 0.393, Val loss 0.523\n",
      "Ep 1 (Step 000100): Train loss 0.389, Val loss 0.520\n",
      "Ep 1 (Step 000105): Train loss 0.477, Val loss 0.518\n",
      "Ep 1 (Step 000110): Train loss 0.462, Val loss 0.510\n",
      "Ep 1 (Step 000115): Train loss 0.407, Val loss 0.510\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked by the chef every day.<|im_end|>\n",
      "Ep 2 (Step 000120): Train loss 0.369, Val loss 0.511\n",
      "Ep 2 (Step 000125): Train loss 0.379, Val loss 0.515\n",
      "Ep 2 (Step 000130): Train loss 0.392, Val loss 0.515\n",
      "Ep 2 (Step 000135): Train loss 0.345, Val loss 0.513\n",
      "Ep 2 (Step 000140): Train loss 0.337, Val loss 0.512\n",
      "Ep 2 (Step 000145): Train loss 0.314, Val loss 0.511\n",
      "Ep 2 (Step 000150): Train loss 0.328, Val loss 0.505\n",
      "Ep 2 (Step 000155): Train loss 0.380, Val loss 0.501\n",
      "Ep 2 (Step 000160): Train loss 0.356, Val loss 0.500\n",
      "Ep 2 (Step 000165): Train loss 0.349, Val loss 0.496\n",
      "Ep 2 (Step 000170): Train loss 0.306, Val loss 0.495\n",
      "Ep 2 (Step 000175): Train loss 0.303, Val loss 0.496\n",
      "Ep 2 (Step 000180): Train loss 0.343, Val loss 0.494\n",
      "Ep 2 (Step 000185): Train loss 0.352, Val loss 0.491\n",
      "Ep 2 (Step 000190): Train loss 0.317, Val loss 0.487\n",
      "Ep 2 (Step 000195): Train loss 0.282, Val loss 0.479\n",
      "Ep 2 (Step 000200): Train loss 0.266, Val loss 0.476\n",
      "Ep 2 (Step 000205): Train loss 0.308, Val loss 0.473\n",
      "Ep 2 (Step 000210): Train loss 0.315, Val loss 0.469\n",
      "Ep 2 (Step 000215): Train loss 0.348, Val loss 0.470\n",
      "Ep 2 (Step 000220): Train loss 0.254, Val loss 0.481\n",
      "Ep 2 (Step 000225): Train loss 0.315, Val loss 0.488\n",
      "Ep 2 (Step 000230): Train loss 0.273, Val loss 0.486\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked by the chef every day.<|im_end|>\n",
      "Training completed in 1.50 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00004, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulus clouds.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test some responses\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_generate(encoded)\n",
    "    # outputs = model.generate(encoded, max_new_tokens=256, temperature=0.6, top_p=0.92, do_sample=True)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    # print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .replace(tokenizer.eos_token, \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model and responses for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [00:46<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save all responses for future evaluations\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_generate(encoded)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .replace(tokenizer.eos_token, \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# file_name = \"smollm-sft-epoch-5.pth\"\n",
    "# torch.save(model.state_dict(), file_name)\n",
    "# print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
