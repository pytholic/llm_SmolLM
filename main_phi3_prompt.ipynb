{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import json\n",
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Apply phi-3 prompt style\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"<|user|>\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "freind --> friend\n",
      "\n",
      "<|assistant|>\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[0])\n",
    "desired_response = f\"\\n\\n<|assistant|>\\n{data[0]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Partitioning the dataset\n",
    "\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1) # 10%\n",
    "val_portion = len(data) - train_portion - test_portion # 5%\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching the dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n<|assistant|>\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "49152\n"
     ]
    }
   ],
   "source": [
    "# Get eos token id (will be used for padding also)\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-135M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=\"./.cache\")\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 0, 0, 0],\n",
      "        [7, 8, 9, 0, 0]]), tensor([[   1,    2,    3,    4,    0],\n",
      "        [   6,    0, -100, -100, -100],\n",
      "        [   8,    9,    0, -100, -100]]))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=\"./.cache\", max_length=1024).to(device)\n",
    "model_generate = partial(model.generate, max_new_tokens=256, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lunit/home/pytholic/miniconda3/envs/llm_smollm/lib/python3.11/site-packages/transformers/generation/utils.py:1376: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "**Step 5: Adding the Active Voice**\n",
      "\n",
      "* **Active Voice**: The active voice describes the subject doing the action.\n",
      "* **Active Voice**: The active voice is used when the subject performs the action.\n",
      "* **Active Voice**: The active voice is used when the subject is doing the action.\n",
      "\n",
      "Example:\n",
      "\n",
      "* The chef cooks the meal every day.\n",
      "* The chef cooks the meal every day.\n",
      "\n",
      "**Step 6: Adding the Passive Voice**\n",
      "\n",
      "* **Passive Voice**: The passive voice describes the subject as the receiver of the action.\n",
      "* **Passive Voice**: The passive voice is used when the subject is the receiver of the action.\n",
      "* **Passive Voice**: The passive voice is used when the subject is the receiver of the action.\n",
      "\n",
      "Example:\n",
      "\n",
      "* The chef cooks the meal every day.\n",
      "* The chef cooks the meal every day.\n",
      "\n",
      "**Step 7: Adding the Passive Voice**\n",
      "\n",
      "* **Passive Voice**: The passive voice describes the subject as the receiver of the action.\n",
      "* **Passive Voice**: The passive voice is used when the subject is the receiver of the action.\n",
      "* **Passive Voice**: The\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model_generate(inputs)\n",
    "outputs = tokenizer.decode(outputs[0])\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    outputs = model(input_batch)\n",
    "    logits = outputs.logits \n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "#     inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "# outputs = model.generate(inputs, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True, output_scores=True, return_dict_in_generate=True)\n",
    "# outputs = tokenizer.decode(outputs.sequences[0])\n",
    "# print(outputs)\n",
    "    encoded = tokenizer.encode(start_context, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_generate(encoded)\n",
    "        decoded_text = tokenizer.decode(outputs[0])\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.976854372024536\n",
      "Validation loss: 2.9908335208892822\n"
     ]
    }
   ],
   "source": [
    "# check the initial loss\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.617, Val loss 2.646\n",
      "Ep 1 (Step 000005): Train loss 1.715, Val loss 1.592\n",
      "Ep 1 (Step 000010): Train loss 1.098, Val loss 1.293\n",
      "Ep 1 (Step 000015): Train loss 1.074, Val loss 1.195\n",
      "Ep 1 (Step 000020): Train loss 0.916, Val loss 1.137\n",
      "Ep 1 (Step 000025): Train loss 0.947, Val loss 1.095\n",
      "Ep 1 (Step 000030): Train loss 1.048, Val loss 1.069\n",
      "Ep 1 (Step 000035): Train loss 0.987, Val loss 1.037\n",
      "Ep 1 (Step 000040): Train loss 0.872, Val loss 1.023\n",
      "Ep 1 (Step 000045): Train loss 0.799, Val loss 1.007\n",
      "Ep 1 (Step 000050): Train loss 0.848, Val loss 0.990\n",
      "Ep 1 (Step 000055): Train loss 0.979, Val loss 0.975\n",
      "Ep 1 (Step 000060): Train loss 0.937, Val loss 0.954\n",
      "Ep 1 (Step 000065): Train loss 0.822, Val loss 0.941\n",
      "Ep 1 (Step 000070): Train loss 0.738, Val loss 0.930\n",
      "Ep 1 (Step 000075): Train loss 0.787, Val loss 0.928\n",
      "Ep 1 (Step 000080): Train loss 0.831, Val loss 0.927\n",
      "Ep 1 (Step 000085): Train loss 0.692, Val loss 0.919\n",
      "Ep 1 (Step 000090): Train loss 0.655, Val loss 0.901\n",
      "Ep 1 (Step 000095): Train loss 0.704, Val loss 0.895\n",
      "Ep 1 (Step 000100): Train loss 0.640, Val loss 0.889\n",
      "Ep 1 (Step 000105): Train loss 0.798, Val loss 0.885\n",
      "Ep 1 (Step 000110): Train loss 0.764, Val loss 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000115): Train loss 0.693, Val loss 0.873\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|assistant|> The chef cooks the meal every day.<|endoftext|>\n",
      "Ep 2 (Step 000120): Train loss 0.612, Val loss 0.869\n",
      "Ep 2 (Step 000125): Train loss 0.644, Val loss 0.868\n",
      "Ep 2 (Step 000130): Train loss 0.683, Val loss 0.861\n",
      "Ep 2 (Step 000135): Train loss 0.585, Val loss 0.858\n",
      "Ep 2 (Step 000140): Train loss 0.602, Val loss 0.860\n",
      "Ep 2 (Step 000145): Train loss 0.540, Val loss 0.857\n",
      "Ep 2 (Step 000150): Train loss 0.553, Val loss 0.848\n",
      "Ep 2 (Step 000155): Train loss 0.643, Val loss 0.847\n",
      "Ep 2 (Step 000160): Train loss 0.618, Val loss 0.844\n",
      "Ep 2 (Step 000165): Train loss 0.614, Val loss 0.843\n",
      "Ep 2 (Step 000170): Train loss 0.552, Val loss 0.840\n",
      "Ep 2 (Step 000175): Train loss 0.528, Val loss 0.839\n",
      "Ep 2 (Step 000180): Train loss 0.610, Val loss 0.836\n",
      "Ep 2 (Step 000185): Train loss 0.611, Val loss 0.837\n",
      "Ep 2 (Step 000190): Train loss 0.548, Val loss 0.829\n",
      "Ep 2 (Step 000195): Train loss 0.514, Val loss 0.812\n",
      "Ep 2 (Step 000200): Train loss 0.499, Val loss 0.811\n",
      "Ep 2 (Step 000205): Train loss 0.532, Val loss 0.804\n",
      "Ep 2 (Step 000210): Train loss 0.542, Val loss 0.803\n",
      "Ep 2 (Step 000215): Train loss 0.640, Val loss 0.803\n",
      "Ep 2 (Step 000220): Train loss 0.451, Val loss 0.807\n",
      "Ep 2 (Step 000225): Train loss 0.561, Val loss 0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2 (Step 000230): Train loss 0.495, Val loss 0.808\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|assistant|> The meal is cooked every day by the chef.<|endoftext|>\n",
      "Training completed in 0.60 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00004, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Rewrite the sentence using a simile.\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is typically associated with clouds.\n",
      "-------------------------------------\n",
      "<|user|>\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test some responses\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_generate(encoded)\n",
    "    # outputs = model.generate(encoded, max_new_tokens=256, temperature=0.6, top_p=0.92, do_sample=True)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"<|im_start|>\", \"\")\n",
    "        .replace(\"<|im_end|>\", \"\")\n",
    "        .replace(\"<|assistant|>\", \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model and responses for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                            | 0/110 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  1%|                                                                                                                                                                                                                                                 | 1/110 [00:00<00:42,  2.54it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  2%|                                                                                                                                                                                                                                               | 2/110 [00:00<00:40,  2.70it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  3%|                                                                                                                                                                                                                                             | 3/110 [00:01<00:44,  2.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  4%|                                                                                                                                                                                                                                           | 4/110 [00:01<00:41,  2.55it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  5%|                                                                                                                                                                                                                                         | 5/110 [00:01<00:37,  2.79it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  5%|                                                                                                                                                                                                                                      | 6/110 [00:02<00:37,  2.75it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  6%|                                                                                                                                                                                                                                    | 7/110 [00:04<01:27,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  7%|                                                                                                                                                                                                                                  | 8/110 [00:04<01:10,  1.45it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  8%|                                                                                                                                                                                                                                | 9/110 [00:04<01:02,  1.61it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  9%|                                                                                                                                                                                                                             | 10/110 [00:05<00:58,  1.72it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 10%|                                                                                                                                                                                                                          | 11/110 [00:05<00:50,  1.98it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 11%|                                                                                                                                                                                                                        | 12/110 [00:06<00:46,  2.13it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 12%|                                                                                                                                                                                                                      | 13/110 [00:06<00:41,  2.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 13%|                                                                                                                                                                                                                    | 14/110 [00:06<00:39,  2.46it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 14%|                                                                                                                                                                                                                 | 15/110 [00:07<00:44,  2.12it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 15%|                                                                                                                                                                                                               | 16/110 [00:07<00:43,  2.15it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 15%|                                                                                                                                                                                                             | 17/110 [00:08<00:41,  2.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 16%|                                                                                                                                                                                                           | 18/110 [00:08<00:37,  2.47it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 17%|                                                                                                                                                                                                         | 19/110 [00:09<00:38,  2.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 18%|                                                                                                                                                                                                      | 20/110 [00:09<00:37,  2.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 19%|                                                                                                                                                                                                    | 21/110 [00:09<00:35,  2.48it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 20%|                                                                                                                                                                                                  | 22/110 [00:10<00:37,  2.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 21%|                                                                                                                                                                                                | 23/110 [00:10<00:36,  2.41it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 22%|                                                                                                                                                                                              | 24/110 [00:11<00:36,  2.35it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 23%|                                                                                                                                                                                           | 25/110 [00:11<00:36,  2.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 24%|                                                                                                                                                                                         | 26/110 [00:12<00:42,  1.99it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 25%|                                                                                                                                                                                       | 27/110 [00:13<00:49,  1.69it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 25%|                                                                                                                                                                                     | 28/110 [00:13<00:46,  1.78it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 26%|                                                                                                                                                                                   | 29/110 [00:13<00:41,  1.96it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 27%|                                                                                                                                                                                | 30/110 [00:14<00:38,  2.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 28%|                                                                                                                                                                              | 31/110 [00:14<00:36,  2.19it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 29%|                                                                                                                                                                            | 32/110 [00:15<00:32,  2.38it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 30%|                                                                                                                                                                          | 33/110 [00:15<00:37,  2.03it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 31%|                                                                                                                                                                        | 34/110 [00:16<00:35,  2.16it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 32%|                                                                                                                                                                     | 35/110 [00:16<00:33,  2.26it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 33%|                                                                                                                                                                   | 36/110 [00:16<00:32,  2.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 34%|                                                                                                                                                                 | 37/110 [00:17<00:31,  2.35it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 35%|                                                                                                                                                               | 38/110 [00:17<00:29,  2.47it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 35%|                                                                                                                                                            | 39/110 [00:18<00:29,  2.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 36%|                                                                                                                                                          | 40/110 [00:19<00:39,  1.78it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 37%|                                                                                                                                                        | 41/110 [00:19<00:36,  1.91it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 38%|                                                                                                                                                      | 42/110 [00:19<00:34,  1.97it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 39%|                                                                                                                                                    | 43/110 [00:20<00:37,  1.77it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 40%|                                                                                                                                                 | 44/110 [00:21<00:33,  1.94it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 41%|                                                                                                                                               | 45/110 [00:21<00:33,  1.93it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 42%|                                                                                                                                             | 46/110 [00:22<00:31,  2.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 43%|                                                                                                                                           | 47/110 [00:22<00:27,  2.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 44%|                                                                                                                                         | 48/110 [00:22<00:24,  2.49it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 45%|                                                                                                                                      | 49/110 [00:23<00:24,  2.51it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 45%|                                                                                                                                    | 50/110 [00:23<00:20,  2.86it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 46%|                                                                                                                                  | 51/110 [00:23<00:20,  2.94it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 47%|                                                                                                                                | 52/110 [00:23<00:19,  3.01it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 48%|                                                                                                                              | 53/110 [00:24<00:19,  2.95it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 49%|                                                                                                                           | 54/110 [00:24<00:23,  2.42it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 50%|                                                                                                                         | 55/110 [00:25<00:23,  2.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 51%|                                                                                                                       | 56/110 [00:26<00:27,  1.94it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 52%|                                                                                                                     | 57/110 [00:26<00:25,  2.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 53%|                                                                                                                  | 58/110 [00:26<00:22,  2.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 54%|                                                                                                                | 59/110 [00:27<00:21,  2.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 55%|                                                                                                              | 60/110 [00:27<00:20,  2.39it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 55%|                                                                                                            | 61/110 [00:28<00:20,  2.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 56%|                                                                                                          | 62/110 [00:28<00:20,  2.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 57%|                                                                                                       | 63/110 [00:28<00:20,  2.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 58%|                                                                                                     | 64/110 [00:29<00:19,  2.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 59%|                                                                                                   | 65/110 [00:29<00:19,  2.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 60%|                                                                                                 | 66/110 [00:30<00:19,  2.30it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 61%|                                                                                               | 67/110 [00:30<00:17,  2.51it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 62%|                                                                                            | 68/110 [00:30<00:15,  2.72it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 63%|                                                                                          | 69/110 [00:31<00:16,  2.46it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 64%|                                                                                        | 70/110 [00:31<00:16,  2.41it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 65%|                                                                                      | 71/110 [00:32<00:15,  2.45it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 65%|                                                                                    | 72/110 [00:32<00:16,  2.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 66%|                                                                                 | 73/110 [00:33<00:15,  2.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 67%|                                                                               | 74/110 [00:33<00:14,  2.47it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 68%|                                                                             | 75/110 [00:34<00:16,  2.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 69%|                                                                           | 76/110 [00:34<00:17,  1.97it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 70%|                                                                         | 77/110 [00:34<00:14,  2.25it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 71%|                                                                      | 78/110 [00:35<00:14,  2.27it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 72%|                                                                    | 79/110 [00:35<00:13,  2.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 73%|                                                                  | 80/110 [00:36<00:13,  2.22it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 74%|                                                                | 81/110 [00:36<00:11,  2.59it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 75%|                                                             | 82/110 [00:36<00:10,  2.57it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Save all responses for future evaluations\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_generate(encoded)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"<|im_start|>\", \"\")\n",
    "        .replace(\"<|im_end|>\", \"\")\n",
    "        .replace(\"<|assistant|>\", \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# file_name = \"smollm-sft-epoch-5.pth\"\n",
    "# torch.save(model.state_dict(), file_name)\n",
    "# print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
