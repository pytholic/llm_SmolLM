{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import json\n",
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Apply alpaca prompt style\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[0])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Partitioning the dataset\n",
    "\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1) # 10%\n",
    "val_portion = len(data) - train_portion - test_portion # 5%\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching the dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "49152\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-360M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=\"./.cache\")\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 0, 0, 0],\n",
      "        [7, 8, 9, 0, 0]]), tensor([[   1,    2,    3,    4,    0],\n",
      "        [   6,    0, -100, -100, -100],\n",
      "        [   8,    9,    0, -100, -100]]))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 102]) torch.Size([8, 102])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 86]) torch.Size([8, 86])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 95]) torch.Size([8, 95])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=\"./.cache\", max_length=100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lunit/home/pytholic/miniconda3/envs/llm_smollm/lib/python3.11/site-packages/transformers/generation/utils.py:1376: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Use the passive voice to describe the following sentence.\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Use the active voice to describe the following sentence.\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "Use\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True, output_scores=True, return_dict_in_generate=True)\n",
    "outputs = tokenizer.decode(outputs.sequences[0]).replace(\"<|im_end|>\", \"\").strip()\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        # Same initialization that is used for Linear layers in PyTorch\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  \n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A LinearWithLora layer to replace Linear layers\n",
    "\n",
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear): # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else: # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 361,821,120\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "# Freeze the original model params\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    " \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    " \n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 9,485,312\n"
     ]
    }
   ],
   "source": [
    "# replace linear layers\n",
    "\n",
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(49152, 960)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=960, out_features=960, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (k_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=960, out_features=320, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (v_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=960, out_features=320, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (o_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=960, out_features=960, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=960, out_features=2560, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (up_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=960, out_features=2560, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (down_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=2560, out_features=960, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=960, out_features=49152, bias=False)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    outputs = model(input_batch)\n",
    "    logits = outputs.logits \n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = 1024\n",
    "#     inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "# outputs = model.generate(inputs, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True, output_scores=True, return_dict_in_generate=True)\n",
    "# outputs = tokenizer.decode(outputs.sequences[0])\n",
    "# print(outputs)\n",
    "    encoded = tokenizer.encode(start_context, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(encoded, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True)\n",
    "        decoded_text = tokenizer.decode(outputs[0])\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.5462928295135496\n",
      "Validation loss: 2.5460066318511965\n"
     ]
    }
   ],
   "source": [
    "# check the initial loss\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.785, Val loss 1.794\n",
      "Ep 1 (Step 000005): Train loss 0.824, Val loss 0.769\n",
      "Ep 1 (Step 000010): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000015): Train loss 0.574, Val loss 0.641\n",
      "Ep 1 (Step 000020): Train loss 0.501, Val loss 0.633\n",
      "Ep 1 (Step 000025): Train loss 0.535, Val loss 0.614\n",
      "Ep 1 (Step 000030): Train loss 0.585, Val loss 0.595\n",
      "Ep 1 (Step 000035): Train loss 0.564, Val loss 0.586\n",
      "Ep 1 (Step 000040): Train loss 0.479, Val loss 0.578\n",
      "Ep 1 (Step 000045): Train loss 0.470, Val loss 0.580\n",
      "Ep 1 (Step 000050): Train loss 0.490, Val loss 0.571\n",
      "Ep 1 (Step 000055): Train loss 0.578, Val loss 0.563\n",
      "Ep 1 (Step 000060): Train loss 0.541, Val loss 0.547\n",
      "Ep 1 (Step 000065): Train loss 0.481, Val loss 0.541\n",
      "Ep 1 (Step 000070): Train loss 0.415, Val loss 0.540\n",
      "Ep 1 (Step 000075): Train loss 0.429, Val loss 0.541\n",
      "Ep 1 (Step 000080): Train loss 0.445, Val loss 0.544\n",
      "Ep 1 (Step 000085): Train loss 0.390, Val loss 0.541\n",
      "Ep 1 (Step 000090): Train loss 0.374, Val loss 0.531\n",
      "Ep 1 (Step 000095): Train loss 0.371, Val loss 0.528\n",
      "Ep 1 (Step 000100): Train loss 0.372, Val loss 0.526\n",
      "Ep 1 (Step 000105): Train loss 0.454, Val loss 0.528\n",
      "Ep 1 (Step 000110): Train loss 0.441, Val loss 0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000115): Train loss 0.380, Val loss 0.515\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked by the chef every day.<|endoftext|>\n",
      "Ep 2 (Step 000120): Train loss 0.350, Val loss 0.520\n",
      "Ep 2 (Step 000125): Train loss 0.350, Val loss 0.527\n",
      "Ep 2 (Step 000130): Train loss 0.366, Val loss 0.529\n",
      "Ep 2 (Step 000135): Train loss 0.326, Val loss 0.531\n",
      "Ep 2 (Step 000140): Train loss 0.311, Val loss 0.528\n",
      "Ep 2 (Step 000145): Train loss 0.297, Val loss 0.525\n",
      "Ep 2 (Step 000150): Train loss 0.312, Val loss 0.522\n",
      "Ep 2 (Step 000155): Train loss 0.355, Val loss 0.517\n",
      "Ep 2 (Step 000160): Train loss 0.341, Val loss 0.519\n",
      "Ep 2 (Step 000165): Train loss 0.333, Val loss 0.519\n",
      "Ep 2 (Step 000170): Train loss 0.293, Val loss 0.520\n",
      "Ep 2 (Step 000175): Train loss 0.279, Val loss 0.519\n",
      "Ep 2 (Step 000180): Train loss 0.320, Val loss 0.513\n",
      "Ep 2 (Step 000185): Train loss 0.328, Val loss 0.511\n",
      "Ep 2 (Step 000190): Train loss 0.291, Val loss 0.510\n",
      "Ep 2 (Step 000195): Train loss 0.264, Val loss 0.498\n",
      "Ep 2 (Step 000200): Train loss 0.256, Val loss 0.498\n",
      "Ep 2 (Step 000205): Train loss 0.296, Val loss 0.497\n",
      "Ep 2 (Step 000210): Train loss 0.293, Val loss 0.497\n",
      "Ep 2 (Step 000215): Train loss 0.338, Val loss 0.495\n",
      "Ep 2 (Step 000220): Train loss 0.247, Val loss 0.499\n",
      "Ep 2 (Step 000225): Train loss 0.306, Val loss 0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2 (Step 000230): Train loss 0.274, Val loss 0.508\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked by the chef.<|endoftext|>\n",
      "Ep 3 (Step 000235): Train loss 0.295, Val loss 0.511\n",
      "Ep 3 (Step 000240): Train loss 0.276, Val loss 0.518\n",
      "Ep 3 (Step 000245): Train loss 0.268, Val loss 0.529\n",
      "Ep 3 (Step 000250): Train loss 0.236, Val loss 0.533\n",
      "Ep 3 (Step 000255): Train loss 0.240, Val loss 0.527\n",
      "Ep 3 (Step 000260): Train loss 0.249, Val loss 0.526\n",
      "Ep 3 (Step 000265): Train loss 0.242, Val loss 0.518\n",
      "Ep 3 (Step 000270): Train loss 0.234, Val loss 0.515\n",
      "Ep 3 (Step 000275): Train loss 0.232, Val loss 0.510\n",
      "Ep 3 (Step 000280): Train loss 0.233, Val loss 0.525\n",
      "Ep 3 (Step 000285): Train loss 0.261, Val loss 0.533\n",
      "Ep 3 (Step 000290): Train loss 0.247, Val loss 0.537\n",
      "Ep 3 (Step 000295): Train loss 0.231, Val loss 0.528\n",
      "Ep 3 (Step 000300): Train loss 0.229, Val loss 0.519\n",
      "Ep 3 (Step 000305): Train loss 0.238, Val loss 0.518\n",
      "Ep 3 (Step 000310): Train loss 0.237, Val loss 0.521\n",
      "Ep 3 (Step 000315): Train loss 0.220, Val loss 0.519\n",
      "Ep 3 (Step 000320): Train loss 0.219, Val loss 0.518\n",
      "Ep 3 (Step 000325): Train loss 0.205, Val loss 0.517\n",
      "Ep 3 (Step 000330): Train loss 0.203, Val loss 0.516\n",
      "Ep 3 (Step 000335): Train loss 0.211, Val loss 0.524\n",
      "Ep 3 (Step 000340): Train loss 0.227, Val loss 0.525\n",
      "Ep 3 (Step 000345): Train loss 0.234, Val loss 0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked by the chef every day.<|endoftext|>\n",
      "Ep 4 (Step 000350): Train loss 0.212, Val loss 0.539\n",
      "Ep 4 (Step 000355): Train loss 0.194, Val loss 0.552\n",
      "Ep 4 (Step 000360): Train loss 0.217, Val loss 0.561\n",
      "Ep 4 (Step 000365): Train loss 0.213, Val loss 0.557\n",
      "Ep 4 (Step 000370): Train loss 0.231, Val loss 0.549\n",
      "Ep 4 (Step 000375): Train loss 0.224, Val loss 0.548\n",
      "Ep 4 (Step 000380): Train loss 0.190, Val loss 0.549\n",
      "Ep 4 (Step 000385): Train loss 0.212, Val loss 0.548\n",
      "Ep 4 (Step 000390): Train loss 0.206, Val loss 0.550\n",
      "Ep 4 (Step 000395): Train loss 0.184, Val loss 0.554\n",
      "Ep 4 (Step 000400): Train loss 0.201, Val loss 0.555\n",
      "Ep 4 (Step 000405): Train loss 0.209, Val loss 0.556\n",
      "Ep 4 (Step 000410): Train loss 0.182, Val loss 0.551\n",
      "Ep 4 (Step 000415): Train loss 0.207, Val loss 0.543\n",
      "Ep 4 (Step 000420): Train loss 0.199, Val loss 0.541\n",
      "Ep 4 (Step 000425): Train loss 0.196, Val loss 0.538\n",
      "Ep 4 (Step 000430): Train loss 0.202, Val loss 0.538\n",
      "Ep 4 (Step 000435): Train loss 0.203, Val loss 0.544\n",
      "Ep 4 (Step 000440): Train loss 0.176, Val loss 0.552\n",
      "Ep 4 (Step 000445): Train loss 0.181, Val loss 0.545\n",
      "Ep 4 (Step 000450): Train loss 0.179, Val loss 0.539\n",
      "Ep 4 (Step 000455): Train loss 0.189, Val loss 0.542\n",
      "Ep 4 (Step 000460): Train loss 0.197, Val loss 0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked by the chef every day.<|endoftext|>\n",
      "Ep 5 (Step 000465): Train loss 0.194, Val loss 0.550\n",
      "Ep 5 (Step 000470): Train loss 0.186, Val loss 0.561\n",
      "Ep 5 (Step 000475): Train loss 0.181, Val loss 0.565\n",
      "Ep 5 (Step 000480): Train loss 0.183, Val loss 0.569\n",
      "Ep 5 (Step 000485): Train loss 0.192, Val loss 0.571\n",
      "Ep 5 (Step 000490): Train loss 0.186, Val loss 0.566\n",
      "Ep 5 (Step 000495): Train loss 0.191, Val loss 0.554\n",
      "Ep 5 (Step 000500): Train loss 0.179, Val loss 0.546\n",
      "Ep 5 (Step 000505): Train loss 0.191, Val loss 0.546\n",
      "Ep 5 (Step 000510): Train loss 0.187, Val loss 0.551\n",
      "Ep 5 (Step 000515): Train loss 0.167, Val loss 0.558\n",
      "Ep 5 (Step 000520): Train loss 0.177, Val loss 0.565\n",
      "Ep 5 (Step 000525): Train loss 0.187, Val loss 0.571\n",
      "Ep 5 (Step 000530): Train loss 0.192, Val loss 0.569\n",
      "Ep 5 (Step 000535): Train loss 0.153, Val loss 0.562\n",
      "Ep 5 (Step 000540): Train loss 0.181, Val loss 0.558\n",
      "Ep 5 (Step 000545): Train loss 0.177, Val loss 0.547\n",
      "Ep 5 (Step 000550): Train loss 0.174, Val loss 0.540\n",
      "Ep 5 (Step 000555): Train loss 0.178, Val loss 0.535\n",
      "Ep 5 (Step 000560): Train loss 0.187, Val loss 0.541\n",
      "Ep 5 (Step 000565): Train loss 0.171, Val loss 0.548\n",
      "Ep 5 (Step 000570): Train loss 0.172, Val loss 0.557\n",
      "Ep 5 (Step 000575): Train loss 0.175, Val loss 0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked by the chef every day.<|endoftext|>\n",
      "Training completed in 3.22 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00004, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a simile.  ### Input: The car is very fast.  ### Response: The car is as fast as a cheetah.<|endoftext|>\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.<|endoftext|>\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What type of cloud is typically associated with thunderstorms?  ### Response: The type of cloud associated with thunderstorms is cumulus.<|endoftext|>\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is cumulus.<|endoftext|>\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Name the author of 'Pride and Prejudice'.  ### Response: The author of 'Pride and Prejudice' is Jane Austen.<|endoftext|>\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.<|endoftext|>\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test some responses\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(encoded, max_new_tokens=256, do_sample=False)\n",
    "    # outputs = model.generate(encoded, max_new_tokens=256, temperature=0.6, top_p=0.92, do_sample=True)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .replace(tokenizer.eos_token, \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model and responses for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                         | 0/110 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  1%|                                                                                                                               | 1/110 [00:00<01:02,  1.76it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  2%|                                                                                                                              | 2/110 [00:01<01:02,  1.72it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  3%|                                                                                                                             | 3/110 [00:01<01:07,  1.59it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  4%|                                                                                                                            | 4/110 [00:02<01:01,  1.73it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  5%|                                                                                                                           | 5/110 [00:03<01:21,  1.28it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  5%|                                                                                                                          | 6/110 [00:04<01:14,  1.40it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  6%|                                                                                                                        | 7/110 [00:06<02:26,  1.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  7%|                                                                                                                       | 8/110 [00:07<01:54,  1.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  8%|                                                                                                                      | 9/110 [00:08<01:36,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  9%|                                                                                                                    | 10/110 [00:08<01:35,  1.04it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 10%|                                                                                                                   | 11/110 [00:09<01:19,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 11%|                                                                                                                  | 12/110 [00:10<01:11,  1.37it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 12%|                                                                                                                | 13/110 [00:10<01:03,  1.52it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 13%|                                                                                                               | 14/110 [00:10<00:58,  1.64it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 14%|                                                                                                              | 15/110 [00:12<01:23,  1.14it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 15%|                                                                                                             | 16/110 [00:13<01:16,  1.23it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 15%|                                                                                                            | 17/110 [00:13<01:08,  1.36it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 16%|                                                                                                           | 18/110 [00:14<01:00,  1.53it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 17%|                                                                                                          | 19/110 [00:14<00:58,  1.55it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 18%|                                                                                                        | 20/110 [00:15<01:00,  1.49it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 19%|                                                                                                       | 21/110 [00:16<00:56,  1.58it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 20%|                                                                                                      | 22/110 [00:16<00:53,  1.63it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 21%|                                                                                                     | 23/110 [00:17<00:51,  1.67it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 22%|                                                                                                    | 24/110 [00:17<00:47,  1.83it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 23%|                                                                                                   | 25/110 [00:18<00:49,  1.72it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 24%|                                                                                                 | 26/110 [00:19<00:58,  1.43it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 25%|                                                                                                | 27/110 [00:20<01:04,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 25%|                                                                                               | 28/110 [00:20<01:01,  1.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 26%|                                                                                              | 29/110 [00:21<00:55,  1.45it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 27%|                                                                                             | 30/110 [00:22<00:52,  1.54it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 28%|                                                                                            | 31/110 [00:22<00:50,  1.58it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 29%|                                                                                          | 32/110 [00:23<00:46,  1.69it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 30%|                                                                                         | 33/110 [00:24<01:05,  1.18it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 31%|                                                                                        | 34/110 [00:25<00:57,  1.32it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 32%|                                                                                       | 35/110 [00:25<00:52,  1.43it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 33%|                                                                                      | 36/110 [00:26<00:50,  1.48it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 34%|                                                                                     | 37/110 [00:26<00:46,  1.55it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 35%|                                                                                   | 38/110 [00:27<00:43,  1.67it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 35%|                                                                                  | 39/110 [00:27<00:43,  1.63it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 36%|                                                                                 | 40/110 [00:29<00:59,  1.17it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 37%|                                                                                | 41/110 [00:30<00:53,  1.29it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 38%|                                                                               | 42/110 [00:30<00:51,  1.33it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 39%|                                                                              | 43/110 [00:31<00:55,  1.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 40%|                                                                            | 44/110 [00:32<00:53,  1.24it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Save all responses for future evaluations\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(encoded, max_new_tokens=256, do_sample=False)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .replace(tokenizer.eos_token, \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# file_name = \"smollm-sft-lora.pth\"\n",
    "# torch.save(model.state_dict(), file_name)\n",
    "# print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
