{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import json\n",
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# # Apply alpaca prompt style\n",
    "# def format_input(entry):\n",
    "#     instruction_text = (\n",
    "#         f\"Below is an instruction that describes a task. \"\n",
    "#         f\"Write a response that appropriately completes the request.\"\n",
    "#         f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "#     )\n",
    "#     input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "#     return instruction_text + input_text\n",
    "\n",
    "# Apply phi-3 prompt style\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"<|user|>\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "freind --> friend\n",
      "\n",
      "<|assistant|>\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "# model_input = format_input(data[0])\n",
    "# desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "# print(model_input + desired_response)\n",
    "\n",
    "model_input = format_input(data[0])\n",
    "desired_response = f\"\\n\\n<|assistant|>\\n{data[0]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Partitioning the dataset\n",
    "\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1) # 10%\n",
    "val_portion = len(data) - train_portion - test_portion # 5%\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching the dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            # response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            response_text = f\"\\n\\n<|assistant|>\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "49152\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=\"./.cache\")\n",
    "\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 2, 2, 2],\n",
      "        [7, 8, 9, 2, 2]]), tensor([[   1,    2,    3,    4, -100],\n",
      "        [   6,    2, -100, -100, -100],\n",
      "        [   8,    9,    2, -100, -100]]))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=\"./.cache\", max_length=100).to(device)\n",
    "model_generate = partial(model.generate, max_new_tokens=256, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lunit/home/pytholic/miniconda3/envs/llm_smollm/lib/python3.11/site-packages/transformers/generation/utils.py:1376: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "Now, rewrite the sentence using the passive form: 'The chef cooks every day.'\n",
      "\n",
      "The correct sentence is: 'The chef cooks every day.'<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model_generate(inputs)\n",
    "outputs = tokenizer.decode(outputs[0])\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        # Same initialization that is used for Linear layers in PyTorch\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  \n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A LinearWithLora layer to replace Linear layers\n",
    "\n",
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear): # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else: # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 134,515,008\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "# Freeze the original model params\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    " \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    " \n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 5,680,128\n"
     ]
    }
   ],
   "source": [
    "# replace linear layers\n",
    "\n",
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n",
      "    (layers): ModuleList(\n",
      "      (0-29): 30 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=576, out_features=576, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (k_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=576, out_features=192, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (v_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=576, out_features=192, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (o_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=576, out_features=576, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=576, out_features=1536, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (up_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=576, out_features=1536, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (down_proj): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1536, out_features=576, bias=False)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=576, out_features=49152, bias=False)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    outputs = model(input_batch)\n",
    "    logits = outputs.logits \n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = 1024\n",
    "#     inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "# outputs = model.generate(inputs, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True, output_scores=True, return_dict_in_generate=True)\n",
    "# outputs = tokenizer.decode(outputs.sequences[0])\n",
    "# print(outputs)\n",
    "    encoded = tokenizer.encode(start_context, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_generate(encoded)\n",
    "        decoded_text = tokenizer.decode(outputs[0])\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.148827600479126\n",
      "Validation loss: 3.1376442909240723\n"
     ]
    }
   ],
   "source": [
    "# check the initial loss\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.188, Val loss 2.235\n",
      "Ep 1 (Step 000005): Train loss 1.425, Val loss 1.266\n",
      "Ep 1 (Step 000010): Train loss 1.003, Val loss 1.166\n",
      "Ep 1 (Step 000015): Train loss 0.996, Val loss 1.133\n",
      "Ep 1 (Step 000020): Train loss 0.901, Val loss 1.116\n",
      "Ep 1 (Step 000025): Train loss 0.920, Val loss 1.089\n",
      "Ep 1 (Step 000030): Train loss 1.026, Val loss 1.061\n",
      "Ep 1 (Step 000035): Train loss 0.932, Val loss 1.033\n",
      "Ep 1 (Step 000040): Train loss 0.874, Val loss 1.014\n",
      "Ep 1 (Step 000045): Train loss 0.768, Val loss 1.002\n",
      "Ep 1 (Step 000050): Train loss 0.828, Val loss 0.980\n",
      "Ep 1 (Step 000055): Train loss 0.959, Val loss 0.968\n",
      "Ep 1 (Step 000060): Train loss 0.928, Val loss 0.954\n",
      "Ep 1 (Step 000065): Train loss 0.812, Val loss 0.944\n",
      "Ep 1 (Step 000070): Train loss 0.732, Val loss 0.941\n",
      "Ep 1 (Step 000075): Train loss 0.763, Val loss 0.945\n",
      "Ep 1 (Step 000080): Train loss 0.786, Val loss 0.945\n",
      "Ep 1 (Step 000085): Train loss 0.653, Val loss 0.939\n",
      "Ep 1 (Step 000090): Train loss 0.635, Val loss 0.914\n",
      "Ep 1 (Step 000095): Train loss 0.663, Val loss 0.908\n",
      "Ep 1 (Step 000100): Train loss 0.624, Val loss 0.904\n",
      "Ep 1 (Step 000105): Train loss 0.762, Val loss 0.906\n",
      "Ep 1 (Step 000110): Train loss 0.724, Val loss 0.897\n",
      "Ep 1 (Step 000115): Train loss 0.653, Val loss 0.895\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|assistant|> The chef cooked the meal every day.<|im_end|>\n",
      "Ep 2 (Step 000120): Train loss 0.596, Val loss 0.909\n",
      "Ep 2 (Step 000125): Train loss 0.621, Val loss 0.912\n",
      "Ep 2 (Step 000130): Train loss 0.644, Val loss 0.911\n",
      "Ep 2 (Step 000135): Train loss 0.571, Val loss 0.920\n",
      "Ep 2 (Step 000140): Train loss 0.557, Val loss 0.914\n",
      "Ep 2 (Step 000145): Train loss 0.521, Val loss 0.893\n",
      "Ep 2 (Step 000150): Train loss 0.526, Val loss 0.880\n",
      "Ep 2 (Step 000155): Train loss 0.602, Val loss 0.881\n",
      "Ep 2 (Step 000160): Train loss 0.578, Val loss 0.883\n",
      "Ep 2 (Step 000165): Train loss 0.573, Val loss 0.902\n",
      "Ep 2 (Step 000170): Train loss 0.501, Val loss 0.914\n",
      "Ep 2 (Step 000175): Train loss 0.496, Val loss 0.898\n",
      "Ep 2 (Step 000180): Train loss 0.577, Val loss 0.875\n",
      "Ep 2 (Step 000185): Train loss 0.575, Val loss 0.868\n",
      "Ep 2 (Step 000190): Train loss 0.528, Val loss 0.865\n",
      "Ep 2 (Step 000195): Train loss 0.478, Val loss 0.853\n",
      "Ep 2 (Step 000200): Train loss 0.468, Val loss 0.857\n",
      "Ep 2 (Step 000205): Train loss 0.513, Val loss 0.860\n",
      "Ep 2 (Step 000210): Train loss 0.485, Val loss 0.861\n",
      "Ep 2 (Step 000215): Train loss 0.600, Val loss 0.853\n",
      "Ep 2 (Step 000220): Train loss 0.435, Val loss 0.853\n",
      "Ep 2 (Step 000225): Train loss 0.508, Val loss 0.845\n",
      "Ep 2 (Step 000230): Train loss 0.463, Val loss 0.848\n",
      "<|user|> Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|assistant|> The chef cooks the meal every day.<|im_end|>\n",
      "Training completed in 0.77 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00004, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Rewrite the sentence using a simile.\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "<|user|>\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud that is typically associated with thunderstorms is cumulus.\n",
      "-------------------------------------\n",
      "<|user|>\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test some responses\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_generate(encoded)\n",
    "    # outputs = model.generate(encoded, max_new_tokens=256, temperature=0.6, top_p=0.92, do_sample=True)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    # print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    # response_text = (\n",
    "    #     decoded_text[len(input_text):]\n",
    "    #     .replace(\"### Response:\", \"\")\n",
    "    #     .replace(tokenizer.eos_token, \"\")\n",
    "    #     .strip()\n",
    "    # )\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"<|im_start|>\", \"\")\n",
    "        .replace(\"<|im_end|>\", \"\")\n",
    "        .replace(\"<|assistant|>\", \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model and responses for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:15<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save all responses for future evaluations\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_generate(encoded)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    # response_text = (\n",
    "    #     decoded_text[len(input_text):]\n",
    "    #     .replace(\"### Response:\", \"\")\n",
    "    #     .replace(tokenizer.eos_token, \"\")\n",
    "    #     .strip()\n",
    "    # )\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"<|im_start|>\", \"\")\n",
    "        .replace(\"<|im_end|>\", \"\")\n",
    "        .replace(\"<|assistant|>\", \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# file_name = \"smollm-sft-lora.pth\"\n",
    "# torch.save(model.state_dict(), file_name)\n",
    "# print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
