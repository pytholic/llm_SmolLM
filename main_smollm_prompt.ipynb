{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The goal of this notebook is to test with original SMolLM prompt style instead of previously used alpaca prompt style.\n",
    "\n",
    "Example:\n",
    "```plain\n",
    "<|im_start|>user\n",
    "Instruction: Evaluate the following phrase by transforming it into the spelling given. \n",
    "freind --> friend<|im_end|>\n",
    "<|im_start|>assistant\n",
    "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|im_end|>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import json\n",
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Apply smollm prompt style\n",
    "def format_input(entry):\n",
    "    input_text = [{\"role\": \"user\", \"content\": f\"{entry['instruction']} \\n{entry['input']}\"}]\n",
    "    return input_text\n",
    "\n",
    "def format_output(entry):\n",
    "    output_text = [{\"role\": \"assistant\", \"content\": f\"{entry['output']}\"}]\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Evaluate the following phrase by transforming it into the spelling given. \n",
      "freind --> friend<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-360M-Instruct\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint+\"-Instruct\", cache_dir=\"./.cache\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=\"./.cache\")\n",
    "\n",
    "\n",
    "instruction_text = format_input(data[0])\n",
    "model_input = tokenizer.apply_chat_template(instruction_text, tokenize=False)\n",
    "output_text = format_output(data[0])\n",
    "desired_response = tokenizer.apply_chat_template(output_text, tokenize=False)\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Partitioning the dataset\n",
    "\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1) # 10%\n",
    "val_portion = len(data) - train_portion - test_portion # 5%\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching the dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            input_text = format_input(entry)\n",
    "            input_text = tokenizer.apply_chat_template(input_text, tokenize=False)\n",
    "            output_text = format_output(entry)\n",
    "            output_text = tokenizer.apply_chat_template(output_text, tokenize=False)\n",
    "            full_text = input_text + output_text + \"<|endoftext|>\"\n",
    "            \n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "49152\n"
     ]
    }
   ],
   "source": [
    "# Get eos token id (will be used for padding also)\n",
    "print(tokenizer.eos_token_id)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 2, 2, 2],\n",
      "        [7, 8, 9, 2, 2]]), tensor([[   1,    2,    3,    4, -100],\n",
      "        [   6,    2, -100, -100, -100],\n",
      "        [   8,    9,    2, -100, -100]]))\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 40]) torch.Size([8, 40])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 39]) torch.Size([8, 39])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 39]) torch.Size([8, 39])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 51]) torch.Size([8, 51])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 39]) torch.Size([8, 39])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 54]) torch.Size([8, 54])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 41]) torch.Size([8, 41])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 52]) torch.Size([8, 52])\n",
      "torch.Size([8, 40]) torch.Size([8, 40])\n",
      "torch.Size([8, 48]) torch.Size([8, 48])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 39]) torch.Size([8, 39])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 46]) torch.Size([8, 46])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 39]) torch.Size([8, 39])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 45]) torch.Size([8, 45])\n",
      "torch.Size([8, 50]) torch.Size([8, 50])\n",
      "torch.Size([8, 40]) torch.Size([8, 40])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 49]) torch.Size([8, 49])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 47]) torch.Size([8, 47])\n",
      "torch.Size([8, 55]) torch.Size([8, 55])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 43]) torch.Size([8, 43])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 44]) torch.Size([8, 44])\n",
      "torch.Size([8, 42]) torch.Size([8, 42])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 53]) torch.Size([8, 53])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=\"./.cache\", max_length=1024).to(device)\n",
    "model_generate = partial(model.generate, max_new_tokens=256, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' \n",
      "<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "instruction_text = format_input(val_data[0])\n",
    "input_text = tokenizer.apply_chat_template(instruction_text, tokenize=False)\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lunit/home/pytholic/miniconda3/envs/llm_smollm/lib/python3.11/site-packages/transformers/generation/utils.py:1376: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' \n",
      "<|im_end|>\n",
      "\n",
      "```\n",
      "\n",
      "I'm not sure if this is the right way to do it, but I'm trying to do it in a way that I can easily understand.\n",
      "\n",
      "I'm not sure if this is the right way to do it, but I'm trying to do it in a way that I can easily understand.\n",
      "\n",
      "I'm not sure if this is the right way to do it, but I'm trying to do it in a way that I can easily understand.\n",
      "\n",
      "```\n",
      "#include \n",
      "#include \n",
      "#include \n",
      "#include \n",
      "#include \n",
      "\n",
      "using namespace std;\n",
      "\n",
      "class Chef\n",
      "{\n",
      "public:\n",
      " Chef()\n",
      " {\n",
      " cout << \"Chef cooks the meal every day.\" << endl;\n",
      " }\n",
      " void cook()\n",
      " {\n",
      " cout << \"Chef cooks the meal every day.\" << endl;\n",
      " }\n",
      " void eat()\n",
      " {\n",
      " cout << \"Chef eats the meal.\" << endl;\n",
      " }\n",
      " void sleep()\n",
      " {\n",
      " cout << \"Chef sleeps.\" << endl;\n",
      " }\n",
      " void eat\\_food()\n",
      " {\n",
      " cout << \"Chef eats the food.\" << endl;\n",
      " }\n",
      " void\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model_generate(inputs)\n",
    "outputs = tokenizer.decode(outputs[0])\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    outputs = model(input_batch)\n",
    "    logits = outputs.logits \n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "#     inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "# outputs = model.generate(inputs, max_new_tokens=100, temperature=0.6, top_p=0.92, do_sample=True, output_scores=True, return_dict_in_generate=True)\n",
    "# outputs = tokenizer.decode(outputs.sequences[0])\n",
    "# print(outputs)\n",
    "    start_context = tokenizer.apply_chat_template(start_context, tokenize=False)\n",
    "    encoded = tokenizer.encode(start_context, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_generate(encoded)\n",
    "        decoded_text = tokenizer.decode(outputs[0])\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.4800104141235355\n",
      "Validation loss: 4.417223596572876\n"
     ]
    }
   ],
   "source": [
    "# check the initial loss\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 4.055, Val loss 3.920\n",
      "Ep 1 (Step 000005): Train loss 2.705, Val loss 2.598\n",
      "Ep 1 (Step 000010): Train loss 1.857, Val loss 2.018\n",
      "Ep 1 (Step 000015): Train loss 1.597, Val loss 1.724\n",
      "Ep 1 (Step 000020): Train loss 1.227, Val loss 1.486\n",
      "Ep 1 (Step 000025): Train loss 1.193, Val loss 1.328\n",
      "Ep 1 (Step 000030): Train loss 1.203, Val loss 1.210\n",
      "Ep 1 (Step 000035): Train loss 1.115, Val loss 1.118\n",
      "Ep 1 (Step 000040): Train loss 0.967, Val loss 1.063\n",
      "Ep 1 (Step 000045): Train loss 0.869, Val loss 1.025\n",
      "Ep 1 (Step 000050): Train loss 0.872, Val loss 0.988\n",
      "Ep 1 (Step 000055): Train loss 0.986, Val loss 0.951\n",
      "Ep 1 (Step 000060): Train loss 0.985, Val loss 0.929\n",
      "Ep 1 (Step 000065): Train loss 0.880, Val loss 0.915\n",
      "Ep 1 (Step 000070): Train loss 0.759, Val loss 0.895\n",
      "Ep 1 (Step 000075): Train loss 0.762, Val loss 0.889\n",
      "Ep 1 (Step 000080): Train loss 0.813, Val loss 0.875\n",
      "Ep 1 (Step 000085): Train loss 0.661, Val loss 0.869\n",
      "Ep 1 (Step 000090): Train loss 0.626, Val loss 0.843\n",
      "Ep 1 (Step 000095): Train loss 0.637, Val loss 0.834\n",
      "Ep 1 (Step 000100): Train loss 0.613, Val loss 0.835\n",
      "Ep 1 (Step 000105): Train loss 0.764, Val loss 0.824\n",
      "Ep 1 (Step 000110): Train loss 0.749, Val loss 0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000115): Train loss 0.639, Val loss 0.801\n",
      "<|im_start|>user Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|im_end|> <|im_start|>assistant The meal is cooked by the chef every day.<|endoftext|>\n",
      "Ep 2 (Step 000120): Train loss 0.588, Val loss 0.805\n",
      "Ep 2 (Step 000125): Train loss 0.613, Val loss 0.807\n",
      "Ep 2 (Step 000130): Train loss 0.618, Val loss 0.792\n",
      "Ep 2 (Step 000135): Train loss 0.531, Val loss 0.788\n",
      "Ep 2 (Step 000140): Train loss 0.539, Val loss 0.794\n",
      "Ep 2 (Step 000145): Train loss 0.498, Val loss 0.795\n",
      "Ep 2 (Step 000150): Train loss 0.503, Val loss 0.789\n",
      "Ep 2 (Step 000155): Train loss 0.615, Val loss 0.779\n",
      "Ep 2 (Step 000160): Train loss 0.561, Val loss 0.772\n",
      "Ep 2 (Step 000165): Train loss 0.549, Val loss 0.771\n",
      "Ep 2 (Step 000170): Train loss 0.510, Val loss 0.775\n",
      "Ep 2 (Step 000175): Train loss 0.474, Val loss 0.775\n",
      "Ep 2 (Step 000180): Train loss 0.559, Val loss 0.770\n",
      "Ep 2 (Step 000185): Train loss 0.524, Val loss 0.769\n",
      "Ep 2 (Step 000190): Train loss 0.494, Val loss 0.758\n",
      "Ep 2 (Step 000195): Train loss 0.445, Val loss 0.742\n",
      "Ep 2 (Step 000200): Train loss 0.434, Val loss 0.740\n",
      "Ep 2 (Step 000205): Train loss 0.487, Val loss 0.738\n",
      "Ep 2 (Step 000210): Train loss 0.479, Val loss 0.740\n",
      "Ep 2 (Step 000215): Train loss 0.564, Val loss 0.745\n",
      "Ep 2 (Step 000220): Train loss 0.412, Val loss 0.756\n",
      "Ep 2 (Step 000225): Train loss 0.508, Val loss 0.764\n",
      "Ep 2 (Step 000230): Train loss 0.431, Val loss 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user Convert the active sentence to passive: 'The chef cooks the meal every day.'  <|im_end|> <|im_start|>assistant The meal is cooked by the chef every day. <|endoftext|>\n",
      "Training completed in 1.17 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00004, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Rewrite the sentence using a simile. \n",
      "The car is very fast.<|im_end|>\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> assistant\n",
      "The car is as fast as a cheetah.\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "What type of cloud is typically associated with thunderstorms? \n",
      "<|im_end|>\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> assistant\n",
      "The type of cloud typically associated with thunderstorms is cumulus clouds. Cumulus clouds are the most common type of cloud during thunderstorms.\n",
      "-------------------------------------\n",
      "<|im_start|>user\n",
      "Name the author of 'Pride and Prejudice'. \n",
      "<|im_end|>\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> assistant\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test some responses\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    input_text = tokenizer.apply_chat_template(input_text, tokenize=False)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_generate(encoded)\n",
    "    # outputs = model.generate(encoded, max_new_tokens=256, temperature=0.6, top_p=0.92, do_sample=True)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"<|im_start|>\", \"\")\n",
    "        .replace(\"<|im_end|>\", \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text.replace(\"<|endoftext|>\", \"\").strip())\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model and responses for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all responses for future evaluations\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "    input_text = tokenizer.apply_chat_template(input_text, tokenize=False)\n",
    "    encoded = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(encoded, max_new_tokens=256, do_sample=False)\n",
    "    decoded_text = tokenizer.decode(outputs[0])\n",
    "    response_text = (\n",
    "        decoded_text[len(input_text):]\n",
    "        .replace(\"<|im_start|>\", \"\")\n",
    "        .replace(\"<|im_end|>\", \"\")\n",
    "        .replace(\"<|endoftext|>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# file_name = \"smollm-sft.pth\"\n",
    "# torch.save(model.state_dict(), file_name)\n",
    "# print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
